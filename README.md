# MIT-graph-challenge
## Problem
DNNs are widely popular framework in various fields. Along with its flexibility and accuracy, te restriction is computation complexity.
The DNN inference time can be a bottleneck for executional limit. Thus to anable complex DNN, we can use parallel archietecture to 
leverage the computational time of inference. 
## Solution
We have designed CUDA kernels for the inference calculation of the DNN. Which make use use of GPU's paralllel archietecture and gives 
considerable speed-up. ***More information regarding dataset,solution or results can be seen in REPORT.pdf***.
